<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Классификация, регрессия и другие алгоритмы Data Mining с использованием R</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Реализация алгоритмов Data Mining с использованием R">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Классификация, регрессия и другие алгоритмы Data Mining с использованием R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://ranalytics.github.io/data-mining/" />
  
  <meta property="og:description" content="Реализация алгоритмов Data Mining с использованием R" />
  <meta name="github-repo" content="ranalytics/data-mining" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Классификация, регрессия и другие алгоритмы Data Mining с использованием R" />
  
  <meta name="twitter:description" content="Реализация алгоритмов Data Mining с использованием R" />
  

<meta name="author" content="Шитиков В. К., Мастицкий С. Э.">


<meta name="date" content="2017-04-07">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="034-Handling-Missing-Values.html">
<link rel="next" href="041-Regression-Models.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Аннотация</a></li>
<li class="chapter" data-level="1" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html"><i class="fa fa-check"></i><b>1</b> Реализация моделей Data Mining в среде R (вместо предисловия)</a><ul>
<li class="chapter" data-level="1.1" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#section_1_1"><i class="fa fa-check"></i><b>1.1</b> Data Mining как направление анализа данных</a><ul>
<li class="chapter" data-level="1.1.1" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#sec_1_1_1"><i class="fa fa-check"></i><b>1.1.1</b> От статистического анализа разового эксперимента к Data Mining</a></li>
<li class="chapter" data-level="1.1.2" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#sec_1_1_2"><i class="fa fa-check"></i><b>1.1.2</b> Принципиальная множественность моделей окружающего мира</a></li>
<li class="chapter" data-level="1.1.3" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#sec_1_1_3"><i class="fa fa-check"></i><b>1.1.3</b> Нарастающая множественность алгоритмов построения моделей</a></li>
<li class="chapter" data-level="1.1.4" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#sec_1_1_4"><i class="fa fa-check"></i><b>1.1.4</b> Типы и характеристики групп моделей Data Mining</a></li>
<li class="chapter" data-level="1.1.5" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#sec_1_1_5"><i class="fa fa-check"></i><b>1.1.5</b> Природа многомерного отклика и его моделирование</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="012-R-Intro.html"><a href="012-R-Intro.html"><i class="fa fa-check"></i><b>1.2</b> Статистическая среда R и ее использование в Data Mining</a></li>
<li class="chapter" data-level="1.3" data-path="013-What-This-Book-Is-About.html"><a href="013-What-This-Book-Is-About.html"><i class="fa fa-check"></i><b>1.3</b> О чем эта книга и чего в ней нет</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="021-Model-Quality-Criteria.html"><a href="021-Model-Quality-Criteria.html"><i class="fa fa-check"></i><b>2</b> Статистические модели: критерии и методы оценивания их качества</a><ul>
<li class="chapter" data-level="2.1" data-path="021-Model-Quality-Criteria.html"><a href="021-Model-Quality-Criteria.html#sec_2_1"><i class="fa fa-check"></i><b>2.1</b> Основные шаги построения и верификации моделей</a></li>
<li class="chapter" data-level="2.2" data-path="022-Resampling-Techniques.html"><a href="022-Resampling-Techniques.html"><i class="fa fa-check"></i><b>2.2</b> Использование алгоритмов ресэмплинга для тестирования моделей и оптимизации их параметров</a></li>
<li class="chapter" data-level="2.3" data-path="023-Models-for-Class-Prediction.html"><a href="023-Models-for-Class-Prediction.html"><i class="fa fa-check"></i><b>2.3</b> Модели для предсказания класса объектов</a></li>
<li class="chapter" data-level="2.4" data-path="024-Projecting-Data-onto-a-Plane.html"><a href="024-Projecting-Data-onto-a-Plane.html"><i class="fa fa-check"></i><b>2.4</b> Проецирование многомерных данных на плоскости</a></li>
<li class="chapter" data-level="2.5" data-path="025-MV-analysis.html"><a href="025-MV-analysis.html"><i class="fa fa-check"></i><b>2.5</b> Многомерный статистический анализ данных</a></li>
<li class="chapter" data-level="2.6" data-path="026-Clustering-Methods.html"><a href="026-Clustering-Methods.html"><i class="fa fa-check"></i><b>2.6</b> Методы кластеризации</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="031-Intro-to-Caret.html"><a href="031-Intro-to-Caret.html"><i class="fa fa-check"></i><b>3</b> Пакет <code>caret</code> - инструмент построения статистических моделей в R</a><ul>
<li class="chapter" data-level="3.1" data-path="031-Intro-to-Caret.html"><a href="031-Intro-to-Caret.html#---------caret"><i class="fa fa-check"></i><b>3.1</b> Универсальный интерфейс доступа к функциям машинного обучения в пакете <code id="sec_3_1">caret</code></a></li>
<li class="chapter" data-level="3.2" data-path="032-Removing-Predictors.html"><a href="032-Removing-Predictors.html"><i class="fa fa-check"></i><b>3.2</b> Обнаружение и удаление “ненужных” предикторов</a></li>
<li class="chapter" data-level="3.3" data-path="033-Preprocessing.html"><a href="033-Preprocessing.html"><i class="fa fa-check"></i><b>3.3</b> Предварительная обработка: преобразование и групповая трансформация переменных</a></li>
<li class="chapter" data-level="3.4" data-path="034-Handling-Missing-Values.html"><a href="034-Handling-Missing-Values.html"><i class="fa fa-check"></i><b>3.4</b> Заполнение пропущенных значений в данных</a></li>
<li class="chapter" data-level="3.5" data-path="035-The-train-Functions.html"><a href="035-The-train-Functions.html"><i class="fa fa-check"></i><b>3.5</b> Функция <code>train()</code> из пакета <code id="sec_3_5">caret</code></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html"><i class="fa fa-check"></i><b>4</b> Построение регрессионных моделей различного типа</a><ul>
<li class="chapter" data-level="4.1" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html#sec_4_1"><i class="fa fa-check"></i><b>4.1</b> Селекция оптимального набора предикторов линейной модели</a><ul>
<li class="chapter" data-level="4.1.1" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html#sec_4_1_1"><i class="fa fa-check"></i><b>4.1.1</b> Полная регрессионная модель и пошаговая процедура</a></li>
<li class="chapter" data-level="4.1.2" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html#sec_4_1_2"><i class="fa fa-check"></i><b>4.1.2</b> Рекурсивное исключение переменных</a></li>
<li class="chapter" data-level="4.1.3" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html#sec_4_1_3"><i class="fa fa-check"></i><b>4.1.3</b> Генетический алгоритм</a></li>
<li class="chapter" data-level="4.1.4" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html#sec_4_1_4"><i class="fa fa-check"></i><b>4.1.4</b> Тестирование моделей с использованием дополнительного набора данных</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="042-Regularization.html"><a href="042-Regularization.html"><i class="fa fa-check"></i><b>4.2</b> Регуляризация, частные наименьшие квадраты и kNN-регрессия</a><ul>
<li class="chapter" data-level="4.2.1" data-path="042-Regularization.html"><a href="042-Regularization.html#sec_4_2_1"><i class="fa fa-check"></i><b>4.2.1</b> Регрессия по методу “лассо”</a></li>
<li class="chapter" data-level="4.2.2" data-path="042-Regularization.html"><a href="042-Regularization.html#sec_4_2_2"><i class="fa fa-check"></i><b>4.2.2</b> Метод частных наименьших квадратов (PLS)</a></li>
<li class="chapter" data-level="4.2.3" data-path="042-Regularization.html"><a href="042-Regularization.html#sec_4_2_3"><i class="fa fa-check"></i><b>4.2.3</b> Регрессия по методу <em>k</em> ближайших соседей</a></li>
<li class="chapter" data-level="4.2.4" data-path="042-Regularization.html"><a href="042-Regularization.html#sec_4_2_4"><i class="fa fa-check"></i><b>4.2.4</b> Тестирование моделей с использованием дополнительного набора данных</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="043-Decision-Trees.html"><a href="043-Decision-Trees.html"><i class="fa fa-check"></i><b>4.3</b> Построение деревьев регрессии</a><ul>
<li class="chapter" data-level="4.3.1" data-path="043-Decision-Trees.html"><a href="043-Decision-Trees.html#sec_4_3_1"><i class="fa fa-check"></i><b>4.3.1</b> Построение деревьев на основе рекурсивного разбиения</a></li>
<li class="chapter" data-level="4.3.2" data-path="043-Decision-Trees.html"><a href="043-Decision-Trees.html#sec_4_3_2"><i class="fa fa-check"></i><b>4.3.2</b> Построение деревьев с использованием алгортма условного вывода</a></li>
<li class="chapter" data-level="4.3.3" data-path="043-Decision-Trees.html"><a href="043-Decision-Trees.html#sec_4_3_3"><i class="fa fa-check"></i><b>4.3.3</b> Тестирование моделей с использованием дополнительного набора данных</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="044-Ensembles.html"><a href="044-Ensembles.html"><i class="fa fa-check"></i><b>4.4</b> Ансамбли моделей: бэггинг, случайные леса, бустинг</a><ul>
<li class="chapter" data-level="4.4.1" data-path="044-Ensembles.html"><a href="044-Ensembles.html#sec_4_4_1"><i class="fa fa-check"></i><b>4.4.1</b> Бэггинг и случайные леса</a></li>
<li class="chapter" data-level="4.4.2" data-path="044-Ensembles.html"><a href="044-Ensembles.html#sec_4_4_2"><i class="fa fa-check"></i><b>4.4.2</b> Бустинг</a></li>
<li class="chapter" data-level="4.4.3" data-path="044-Ensembles.html"><a href="044-Ensembles.html#sec_4_4_3"><i class="fa fa-check"></i><b>4.4.3</b> Тестирование моделей с использованием дополнительного набора данных</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="045-Comparing-Trees.html"><a href="045-Comparing-Trees.html"><i class="fa fa-check"></i><b>4.5</b> Сравнение построенных моделей и оценка информативности предикторов</a></li>
<li class="chapter" data-level="4.6" data-path="046-MV-Trees.html"><a href="046-MV-Trees.html"><i class="fa fa-check"></i><b>4.6</b> Деревья регрессии с многомерным откликом</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="051-Association-Rules.html"><a href="051-Association-Rules.html"><i class="fa fa-check"></i><b>5</b> Бинарные матрицы и ассоциативные правила</a><ul>
<li class="chapter" data-level="5.1" data-path="051-Association-Rules.html"><a href="051-Association-Rules.html#sec_5_1"><i class="fa fa-check"></i><b>5.1</b> Классификация в бинарных пространствах с использованием классических моделей</a></li>
<li class="chapter" data-level="5.2" data-path="052-Binary-Decision-Trees.html"><a href="052-Binary-Decision-Trees.html"><i class="fa fa-check"></i><b>5.2</b> Бинарные деревья решений</a></li>
<li class="chapter" data-level="5.3" data-path="053-Logic-Rules.html"><a href="053-Logic-Rules.html"><i class="fa fa-check"></i><b>5.3</b> Поиск логических закономерностей в данных</a></li>
<li class="chapter" data-level="5.4" data-path="054-Association-Rules-Algos.html"><a href="054-Association-Rules-Algos.html"><i class="fa fa-check"></i><b>5.4</b> Алгоритмы выделения ассоциативных правил</a></li>
<li class="chapter" data-level="5.5" data-path="055-Traminer.html"><a href="055-Traminer.html"><i class="fa fa-check"></i><b>5.5</b> Анализ последовательностей знаков или событий</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="061-Binary-Classifiers.html"><a href="061-Binary-Classifiers.html"><i class="fa fa-check"></i><b>6</b> Бинарные классификаторы с различными разделяющими поверхностями</a><ul>
<li class="chapter" data-level="6.1" data-path="061-Binary-Classifiers.html"><a href="061-Binary-Classifiers.html#sec_6_1"><i class="fa fa-check"></i><b>6.1</b> Дискриминантный анализ</a></li>
<li class="chapter" data-level="6.2" data-path="062-SVM.html"><a href="062-SVM.html"><i class="fa fa-check"></i><b>6.2</b> Метод опорных векторов</a></li>
<li class="chapter" data-level="6.3" data-path="063-Nonlinear-Borders.html"><a href="063-Nonlinear-Borders.html"><i class="fa fa-check"></i><b>6.3</b> Ядерные функции машины опорных векторов</a></li>
<li class="chapter" data-level="6.4" data-path="064-Classification-Trees.html"><a href="064-Classification-Trees.html"><i class="fa fa-check"></i><b>6.4</b> Деревья классификации, случайный лес и логистическая регрессия</a></li>
<li class="chapter" data-level="6.5" data-path="065-Comparing-Classifiers.html"><a href="065-Comparing-Classifiers.html"><i class="fa fa-check"></i><b>6.5</b> Процедуры сравнения эффективности моделей классификации</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="071-Multiclass-Classification.html"><a href="071-Multiclass-Classification.html"><i class="fa fa-check"></i><b>7</b> Модели классификации для нескольких классов</a><ul>
<li class="chapter" data-level="7.1" data-path="071-Multiclass-Classification.html"><a href="071-Multiclass-Classification.html#sec_7_1"><i class="fa fa-check"></i><b>7.1</b> Ирисы Фишера и метод <em>k</em> ближайших соседей</a></li>
<li class="chapter" data-level="7.2" data-path="072-NBC.html"><a href="072-NBC.html"><i class="fa fa-check"></i><b>7.2</b> Наивный байесовский классификатор</a></li>
<li class="chapter" data-level="7.3" data-path="073-In-Discriminant-Space.html"><a href="073-In-Discriminant-Space.html"><i class="fa fa-check"></i><b>7.3</b> Классификация в линейном дискриминантном пространстве</a></li>
<li class="chapter" data-level="7.4" data-path="074-Nonlinear-Classifiers.html"><a href="074-Nonlinear-Classifiers.html"><i class="fa fa-check"></i><b>7.4</b> Нелинейные классификаторы в R</a></li>
<li class="chapter" data-level="7.5" data-path="075-Multinomial-Logit.html"><a href="075-Multinomial-Logit.html"><i class="fa fa-check"></i><b>7.5</b> Модель мультиномиального логита</a></li>
<li class="chapter" data-level="7.6" data-path="076-NN.html"><a href="076-NN.html"><i class="fa fa-check"></i><b>7.6</b> Классификаторы на основе искусственных нейронных сетей</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="081-Logit-for-Count.html"><a href="081-Logit-for-Count.html"><i class="fa fa-check"></i><b>8</b> Моделирование порядковых и счетных переменных</a><ul>
<li class="chapter" data-level="8.1" data-path="081-Logit-for-Count.html"><a href="081-Logit-for-Count.html#sec_8_1"><i class="fa fa-check"></i><b>8.1</b> Модель логита для порядковой переменной</a></li>
<li class="chapter" data-level="8.2" data-path="082-NN-with-Caret.html"><a href="082-NN-with-Caret.html"><i class="fa fa-check"></i><b>8.2</b> Настройка параметров нейронных сетей средствами пакета <code id="sec_8_2">caret</code></a></li>
<li class="chapter" data-level="8.3" data-path="083-Model-Complexes.html"><a href="083-Model-Complexes.html"><i class="fa fa-check"></i><b>8.3</b> Методы комплексации модельных прогнозов</a></li>
<li class="chapter" data-level="8.4" data-path="084-GLM-for-Counts.html"><a href="084-GLM-for-Counts.html"><i class="fa fa-check"></i><b>8.4</b> Обобщенные линейные модели для счетных данных</a></li>
<li class="chapter" data-level="8.5" data-path="085-ZIP-for-Counts.html"><a href="085-ZIP-for-Counts.html"><i class="fa fa-check"></i><b>8.5</b> ZIP- и барьерные модели счетных данных</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="091-Data-Transformation.html"><a href="091-Data-Transformation.html"><i class="fa fa-check"></i><b>9</b> Методы многомерной ординации</a><ul>
<li class="chapter" data-level="9.1" data-path="091-Data-Transformation.html"><a href="091-Data-Transformation.html#sec_9_1"><i class="fa fa-check"></i><b>9.1</b> Преобразование данных и вычисление матрицы расстояний</a></li>
<li class="chapter" data-level="9.2" data-path="092-Distance-ANOVA.html"><a href="092-Distance-ANOVA.html"><i class="fa fa-check"></i><b>9.2</b> Непараметрический дисперсионный анализ матриц дистанций</a></li>
<li class="chapter" data-level="9.3" data-path="093-Comparing-Diagrams.html"><a href="093-Comparing-Diagrams.html"><i class="fa fa-check"></i><b>9.3</b> Методы ординации объектов и переменных: построение и сравнение диаграмм</a></li>
<li class="chapter" data-level="9.4" data-path="094-Ordination-Factors.html"><a href="094-Ordination-Factors.html"><i class="fa fa-check"></i><b>9.4</b> Оценка связи ординации с внешними факторами</a></li>
<li class="chapter" data-level="9.5" data-path="095-NMDS.html"><a href="095-NMDS.html"><i class="fa fa-check"></i><b>9.5</b> Неметрическое многомерное шкалирование и построение распределения чувствительности видов</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="101-Partitioning-Algos.html"><a href="101-Partitioning-Algos.html"><i class="fa fa-check"></i><b>10</b> Кластерный анализ</a><ul>
<li class="chapter" data-level="10.1" data-path="101-Partitioning-Algos.html"><a href="101-Partitioning-Algos.html#sec_10_1"><i class="fa fa-check"></i><b>10.1</b> Алгоритмы кластеризации, основанные на разделении</a></li>
<li class="chapter" data-level="10.2" data-path="102-H-Clustering.html"><a href="102-H-Clustering.html"><i class="fa fa-check"></i><b>10.2</b> Иерархическая кластеризация</a></li>
<li class="chapter" data-level="10.3" data-path="103-Clustering-Quality.html"><a href="103-Clustering-Quality.html"><i class="fa fa-check"></i><b>10.3</b> Оценка качества кластеризации</a></li>
<li class="chapter" data-level="10.4" data-path="104-Other-Clustering-Methods.html"><a href="104-Other-Clustering-Methods.html"><i class="fa fa-check"></i><b>10.4</b> Другие алгоритмы кластеризации</a><ul>
<li class="chapter" data-level="10.4.1" data-path="104-Other-Clustering-Methods.html"><a href="104-Other-Clustering-Methods.html#sec_10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Иерархическая кластеризация на главные компоненты</a></li>
<li class="chapter" data-level="10.4.2" data-path="104-Other-Clustering-Methods.html"><a href="104-Other-Clustering-Methods.html#sec_10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Метод нечетких <em>k</em> средних (fuzzy analysis clustering)</a></li>
<li class="chapter" data-level="10.4.3" data-path="104-Other-Clustering-Methods.html"><a href="104-Other-Clustering-Methods.html#sec_10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Статистическая модель кластеризации</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="105-Cohonen-Maps.html"><a href="105-Cohonen-Maps.html"><i class="fa fa-check"></i><b>10.5</b> Самоорганизующиеся карты Кохонена</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="111-Rattle-Intro.html"><a href="111-Rattle-Intro.html"><i class="fa fa-check"></i><b>11</b> <code>rattle</code>: графический интерфейс R для реализации алгоритмов Data Mining</a><ul>
<li class="chapter" data-level="11.1" data-path="111-Rattle-Intro.html"><a href="111-Rattle-Intro.html#----rattle"><i class="fa fa-check"></i><b>11.1</b> Начало работы с пакетом <code id="sec_11_1">rattle</code></a></li>
<li class="chapter" data-level="11.2" data-path="112-Descriptive-Stats.html"><a href="112-Descriptive-Stats.html"><i class="fa fa-check"></i><b>11.2</b> Описательная статистика и визуализация данных</a></li>
<li class="chapter" data-level="11.3" data-path="113-Model-Building.html"><a href="113-Model-Building.html"><i class="fa fa-check"></i><b>11.3</b> Построение и тестирование моделей классификации</a></li>
<li class="chapter" data-level="11.4" data-path="114-Descriptive-Models.html"><a href="114-Descriptive-Models.html"><i class="fa fa-check"></i><b>11.4</b> Дескриптивные модели (обучение без учителя)</a><ul>
<li class="chapter" data-level="11.4.1" data-path="114-Descriptive-Models.html"><a href="114-Descriptive-Models.html#sec_11_4_1"><i class="fa fa-check"></i><b>11.4.1</b> Кластерный анализ</a></li>
<li class="chapter" data-level="11.4.2" data-path="114-Descriptive-Models.html"><a href="114-Descriptive-Models.html#sec_11_4_2"><i class="fa fa-check"></i><b>11.4.2</b> Ассоциативные правила</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="120-References.html"><a href="120-References.html"><i class="fa fa-check"></i><b>12</b> Список рекомендуемой литературы</a></li>
<li class="chapter" data-level="" data-path="130-Appendix.html"><a href="130-Appendix.html"><i class="fa fa-check"></i>Приложение: cправочная карта по Data Mining с использованием R</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Классификация, регрессия и другие алгоритмы Data Mining с использованием R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="-train---caret" class="section level2">
<h2><span class="header-section-number">3.5</span> Функция <code>train()</code> из пакета <code id="sec_3_5">caret</code></h2>
<p>Как подчеркивалось ранее в разделе <a href="031-Intro-to-Caret.html#sec_3_1">3.1</a>, пакет <code>caret</code> был разработан как эффективная надстройка, позволяющая унифицировать и интегрировать использование множества различных функций и методов построения моделей классификации и регрессии, представленных в других пакетах R. При этом происходит всестороннее тестирование и оптимизация настраиваемых коэффициентов и гиперпараметров моделей. Эта разработанная единая технология реализована в функции <code>train()</code>, использующей полуавтоматические интеллектуальные подходы и универсальные критерии качества с применением алгоритмов ресэмплинга.</p>
<p>Перед выполнением подгонки модели с помощью функции <code>train()</code> необходимо задать соответствующий алгоритм и всю совокупность условий процесса оптимизации параметров модели, для чего при помощи функции <code>trainControl()</code> создается специальный объект. Вызов этой функции со значениями, принимаемыми по умолчанию, имеет следующий вид:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;boot&quot;</span>, 
             <span class="dt">number =</span> <span class="kw">ifelse</span>(<span class="kw">grepl</span>(<span class="st">&quot;cv&quot;</span>, method), <span class="dv">10</span>, <span class="dv">25</span>), <span class="dt">p =</span> <span class="fl">0.75</span>,
             <span class="dt">repeats =</span> <span class="kw">ifelse</span>(<span class="kw">grepl</span>(<span class="st">&quot;cv&quot;</span>, method), <span class="dv">1</span>, number),
             <span class="dt">search =</span> <span class="st">&quot;grid&quot;</span>, <span class="dt">initialWindow =</span> <span class="ot">NULL</span>, <span class="dt">horizon =</span> <span class="dv">1</span>,
             <span class="dt">fixedWindow =</span> <span class="ot">TRUE</span>, <span class="dt">verboseIter =</span> <span class="ot">FALSE</span>, <span class="dt">returnData =</span> <span class="ot">TRUE</span>,
             <span class="dt">returnResamp =</span> <span class="st">&quot;final&quot;</span>, <span class="dt">savePredictions =</span> <span class="ot">FALSE</span>, 
             <span class="dt">classProbs =</span> <span class="ot">FALSE</span>, <span class="dt">summaryFunction =</span> defaultSummary,
             <span class="dt">selectionFunction =</span> <span class="st">&quot;best&quot;</span>, <span class="dt">seeds =</span> <span class="ot">NA</span>,
             <span class="dt">preProcOptions =</span> <span class="kw">list</span>(<span class="dt">thresh =</span> <span class="fl">0.95</span>, <span class="dt">ICAcomp =</span> <span class="dv">3</span>, <span class="dt">k =</span> <span class="dv">5</span>),
             <span class="dt">sampling =</span> <span class="ot">NULL</span>, <span class="dt">index =</span> <span class="ot">NULL</span>, <span class="dt">indexOut =</span> <span class="ot">NULL</span>,
             <span class="dt">timingSamps =</span> <span class="dv">0</span>, <span class="dt">predictionBounds =</span> <span class="kw">rep</span>(<span class="ot">FALSE</span>, <span class="dv">2</span>), 
             <span class="dt">adaptive =</span> <span class="kw">list</span>(<span class="dt">min =</span> <span class="dv">5</span>, <span class="dt">alpha =</span> <span class="fl">0.05</span>, <span class="dt">method =</span> <span class="st">&quot;gls&quot;</span>, <span class="dt">complete =</span> <span class="ot">TRUE</span>),
             <span class="dt">trim =</span> <span class="ot">FALSE</span>, <span class="dt">allowParallel =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>Остановимся на описании наиболее важных аргументов этой функции:</p>
<ul>
<li><code>method</code> - метод ресэмплинга: <code>&quot;boot&quot;</code>, <code>&quot;boot632&quot;</code>, <code>&quot;cv&quot;</code>, <code>&quot;repeatedcv&quot;</code>, <code>&quot;LOOCV&quot;</code>, <code>&quot;LGOCV&quot;</code> (для повторяющихся разбиений на обучающую и проверочную выборки), <code>&quot;none&quot;</code> (исследуется только модель на обучающей выборке), <code>&quot;oob&quot;</code> (для таких алгоритмов, как случайный лес, бэггинг деревьев и др.), <code>&quot;adaptive_cv&quot;</code>, <code>&quot;adaptive_boot&quot;</code> или <code>&quot;adaptive_LGOCV&quot;</code>;</li>
<li><code>number</code> - задает число итераций ресэмплинга, в частности, число блоков (<code>folds</code>) при перекрестной проверке;</li>
<li><code>repeats</code> - число повторностей (только для <em>k</em>-кратной перекрестной проверки);</li>
<li><code>p</code> - доля обучающей выборки от общего объема при выполнении перекрестной проверки;</li>
<li><code>verboseIter</code> - <code>TRUE</code> означает, что в ходе вычислений <code>caret</code> будет показывать, на каком этапе они находятся (это удобно для оценки оставшегося времени вычислений, которое часто бывает очень большим);</li>
<li><code>search</code> - способ перебора параметров модели (по сетке - <code>&quot;grid&quot;</code>, или случайным назначением - <code>&quot;random&quot;</code>);</li>
<li><code>returnResamp</code> и <code>savePredictions</code> - определяют условия сохранения результатов выполнения ресэмплинга и прогнозируемых значений, т.е. <code>&quot;none&quot;</code>, только для итоговой модели <code>&quot;final&quot;</code> или все <code>&quot;all&quot;</code>;</li>
<li><code>classProbs</code> - <code>TRUE</code> означает, что в процессе вычислений алгоритм будет сохранять данные о вероятностях попадания объекта в каждый класс, а не только конечные метки класса;</li>
<li><code>summaryFunction</code> - определяет функцию, которая вычисляет метрику качества модели при ресэмплинге;</li>
<li><code>selectionFunction</code> - определяет функцию выбора оптимального значения настраиваемого параметра;</li>
<li><code>preProcOptions</code> - список опций, который передается функции предобработки данных <code>preProcess()</code>.</li>
</ul>
<p>Например, при создании объекта <code>ctrl &lt;- trainControl(method = &quot;repeatedcv&quot;, number = 10, repeats = 10)</code> параметры перекрестной проверки будут иметь следующий смысл:</p>
<ul>
<li><code>method = &quot;repeatedcv&quot;</code> означает, что будет использоваться повторная перекрестная проверка (также возможна перекрестная проверка, leave-one-out проверка, и т.д.);</li>
<li><code>number = 10</code> означает, что в процессе перекрестной проверки выборку надо разбивать на 10 равных частей;</li>
<li><code>repeats = 10</code> означает, что повторная перекрестная проверка должна быть запущена 10 раз.</li>
</ul>
<p>Теперь перейдем непосредственно к описанию функции <code>train()</code>, которая имеет следующий формат вызова:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">train</span>(x, y, 
      <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, 
      <span class="dt">preProcess =</span> <span class="ot">NULL</span>, 
      <span class="dt">weights =</span> <span class="ot">NULL</span>,
      <span class="dt">metric =</span> <span class="kw">ifelse</span>(<span class="kw">is.factor</span>(y), <span class="st">&quot;Accuracy&quot;</span>, <span class="st">&quot;RMSE&quot;</span>), 
      <span class="dt">maximize =</span> <span class="kw">ifelse</span>(metric %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;RMSE&quot;</span>, <span class="st">&quot;logLoss&quot;</span>), <span class="ot">FALSE</span>, <span class="ot">TRUE</span>), 
      <span class="dt">trControl =</span> <span class="kw">trainControl</span>(),
      <span class="dt">tuneGrid =</span> <span class="ot">NULL</span>,
      <span class="dt">tuneLength =</span> <span class="dv">3</span>)</code></pre></div>
<p>Исходные данные задаются, как всегда, либо матрицей предикторов x и вектором отклика y, либо объектом formula с указанием таблицы данных data. Следующий аргумент - <code>method</code> - это, в сущности, название модели классификации или регрессии, которую необходимо построить и протестировать. Если выполнить команду names(<code>getModelInfo()</code>), то можно увидеть список из 233 доступных методов (это количество постоянно расширяется). Тот же список, но с различными возможностями поиска и сортировки можно посмотреть по следующим адресам в Интернете:</p>
<p><a href="http://topepo.github.io/caret/modelList.html" class="uri">http://topepo.github.io/caret/modelList.html</a> или<br />
<a href="http://topepo.github.io/caret/bytag.html" class="uri">http://topepo.github.io/caret/bytag.html</a></p>
<p>Можно просмотреть названия всех моделей, которые имеют, например, отношение к линейной регрессии:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)
<span class="kw">ls</span>(<span class="kw">getModelInfo</span>(<span class="dt">model =</span> <span class="st">&quot;lm&quot;</span>))</code></pre></div>
<pre><code>##  [1] &quot;bayesglm&quot;       &quot;elm&quot;            &quot;glm&quot;            &quot;glm.nb&quot;        
##  [5] &quot;glmboost&quot;       &quot;glmnet&quot;         &quot;glmnet_h2o&quot;     &quot;glmStepAIC&quot;    
##  [9] &quot;lm&quot;             &quot;lmStepAIC&quot;      &quot;plsRglm&quot;        &quot;rlm&quot;           
## [13] &quot;vglmAdjCat&quot;     &quot;vglmContRatio&quot;  &quot;vglmCumulative&quot;</code></pre>
<p>С каждым методом связан набор гиперпараметров, подлежащих оптимизации. Можно убедиться в том, что простая линейная регрессия (<code>method = &quot;lm&quot;</code>) не имеет параметров для настройки:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">modelLookup</span>(<span class="st">&quot;lm&quot;</span>)</code></pre></div>
<pre><code>##   model parameter     label forReg forClass probModel
## 1    lm intercept intercept   TRUE    FALSE     FALSE</code></pre>
<p>В свою очередь, деревья решений <code>rpart</code>, которые мы рассмотрим позднее, имеют один параметр для настройки - Complexity Parameter (аббревиатура - <code>cp</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">modelLookup</span>(<span class="st">&quot;rpart&quot;</span>)</code></pre></div>
<pre><code>##   model parameter                label forReg forClass probModel
## 1 rpart        cp Complexity Parameter   TRUE     TRUE      TRUE</code></pre>
<p>Из сообщений функции <code>modelLookup()</code> можно также увидеть, что линейная регрессия не используется для классификации (<code>forClass= FALSE</code>), тогда как <code>rpart</code> (от “Recursive Partitioning and Regression Trees”) можно применять как для построения деревьев регрессии, так и классификации. В последнем случае модель осуществляет не только предсказание класса, но и оценивает апостериорные вероятности (<code>probModel = TRUE</code>).</p>
<p>Метод перекрестной проверки, заданный объектом <code>trControl = trainControl()</code>, обеспечивает сканирование настраиваемых параметров и оценку эффективности модели на каждой итерации по определенным критериям качества. При построении каждой частной модели предварительно осуществляется предобработка данных с использованием методов, перечисленных в <code>preProcess</code> (и с учетом опций <code>preProcOptions</code> объекта <code>trControl</code>).</p>
<p>По умолчанию аргумент <code>metric</code> использует в качестве критерия качества точность предсказания (<code>&quot;Accuracy&quot;</code>) в случае классификации (см. пример, рассмотренный в разделе <a href="033-Preprocessing.html#sec_3_3">3.3</a>) и корень из среднеквадратичного отклонения прогнозируемых значений от наблюдаемых (<code>&quot;RMSE&quot;</code>) для регрессии. Логический аргумент <code>maximize</code> уточняет, должен ли этот критерий быть максимизирован или минимизирован. Другие значения <code>metric</code> вместе с различными значениями аргументов <code>summaryFunction</code> и <code>selectionFunction</code> объекта <code>trControl</code> обеспечивают широкие возможности пользовательского назначения метрик для оценки эффективности моделей.</p>
<p>Количество перебираемых значений настраиваемого параметра задается аргументом <code>tuneLength</code>. Например, чтобы задать 30 повторов оценки параметра <code>cр</code> модели <code>rpart</code> вместо исходных трех, необходимо указать <code>tuneLength = 30</code>. Другой вариант - определить последовательность этих значений в списке, задающем сетку: например, <code>tuneGrid = expand.grid(.cp = 0.5^(1:10))</code>, если заранее известен диапазон, к которому принадлежит оптимизируемое значение.</p>
<p>После завершения перебора всех положенных комбинаций параметров модели создается объект класса <code>train</code>, соответствующие элементы которого можно извлечь с помощью суффикса <code>$</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ls</span>(mytrain)</code></pre></div>
<p>Приведем краткий пример на тему подбора полиномиальной регрессии для описания зависимости электрического сопротивления (Ом) мякоти фруктов киви от процентного содержания в ней сока, который подробно разбирался нами в разделе <a href="021-Model-Quality-Criteria.html#sec_2_1">2.1</a>. Позже (раздел <a href="022-Resampling-Techniques.html#sec_2_2">2.2</a>) мы показали, как найти оптимальную степень полинома <span class="math inline">\(d = 4\)</span> с использованием написанной нами функции скользящего контроля.</p>
<p>К сожалению, функция <code>train()</code> селекцию предикторов для метода <code>&quot;lm&quot;</code> не выполняет и оптимальную степень полинома не настраивает. Но мы можем выполнить любую перекрестную проверку для оценки динамики изменения критериев качества модели - среднеквадратичной ошибки <code>RMSE</code> и среднего коэффициента детерминации <code>RSquared</code> (рис. <a href="035-The-train-Functions.html#fig:fig-3-8">3.8</a>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(DAAG)
<span class="kw">data</span>(<span class="st">&quot;fruitohms&quot;</span>)
<span class="kw">set.seed</span>(<span class="dv">123</span>) 
max.poly &lt;-<span class="st"> </span><span class="dv">7</span>
degree &lt;-<span class="st"> </span><span class="dv">1</span>:max.poly
RSquared &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, max.poly)
RMSE &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, max.poly)

<span class="co"># Выполним 10-кратную кросс-проверку с 10 повторностями</span>
fitControl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,
                           <span class="dt">number =</span> <span class="dv">10</span>, <span class="dt">repeats =</span> <span class="dv">10</span>)

<span class="co"># Тестируем модель для различных степеней:</span>
for (d in degree)  {
    f &lt;-<span class="st"> </span><span class="kw">bquote</span>(juice ~<span class="st"> </span><span class="kw">poly</span>(ohms, .(d)))
    LinearRegressor &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="kw">as.formula</span>(f),
                             <span class="dt">data =</span> fruitohms,
                             <span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">trControl =</span> fitControl)
    RSquared[d] &lt;-<span class="st"> </span>LinearRegressor$results$Rsquared
    RMSE[d] &lt;-<span class="st"> </span>LinearRegressor$results$RMSE
}

<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(gridExtra)
Degree.RegParams &lt;-<span class="st"> </span><span class="kw">data.frame</span>(degree, RSquared, RMSE)
a &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> degree, <span class="dt">y =</span> RSquared),
       <span class="dt">data =</span> Degree.RegParams) +<span class="st"> </span><span class="kw">geom_line</span>()
b &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> degree, <span class="dt">y =</span> RMSE),
       <span class="dt">data =</span> Degree.RegParams) +<span class="st"> </span><span class="kw">geom_line</span>()
<span class="kw">grid.arrange</span>(a, b, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig-3-8"></span>
<img src="035-The-train-Functions_files/figure-html/fig-3-8-1.png" alt="Поиск степени функции полиномиальной регрессии с использованием функции `train()`" width="768" />
<p class="caption">
Рисунок 3.8: Поиск степени функции полиномиальной регрессии с использованием функции <code>train()</code>
</p>
</div>
<p>В отличие от ранее проведенных расчетов, минимум ошибки и максимум коэффициента детерминации имеют место при <span class="math inline">\(d = 5\)</span>.</p>
<p>Если не задавать непосредственно объект <code>trControl</code>, то по умолчанию вместо кросс-проверки функция <code>train()</code> осуществляет бутстреп критериев качества подгонки <code>RMSE</code> и <code>RSquared</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Poly5 &lt;-<span class="st"> </span><span class="kw">train</span>(ohms ~<span class="st"> </span><span class="kw">poly</span>(juice,<span class="dv">5</span>), <span class="dt">data =</span> fruitohms, <span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>)
<span class="kw">summary</span>(Poly5$finalModel)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = .outcome ~ ., data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3363.7  -508.9   -35.8   459.7  2797.7 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         4360.0       83.2  52.406  &lt; 2e-16 ***
## `poly(juice, 5)1` -16750.2      941.3 -17.796  &lt; 2e-16 ***
## `poly(juice, 5)2`   4750.6      941.3   5.047 1.59e-06 ***
## `poly(juice, 5)3`   3945.6      941.3   4.192 5.27e-05 ***
## `poly(juice, 5)4`  -3371.2      941.3  -3.582 0.000492 ***
## `poly(juice, 5)5`   1057.3      941.3   1.123 0.263509    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 941.3 on 122 degrees of freedom
## Multiple R-squared:  0.7539, Adjusted R-squared:  0.7439 
## F-statistic: 74.76 on 5 and 122 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(ohms ~<span class="st"> </span><span class="kw">poly</span>(juice, <span class="dv">5</span>), <span class="dt">data =</span> fruitohms))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ohms ~ poly(juice, 5), data = fruitohms)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3363.7  -508.9   -35.8   459.7  2797.7 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       4360.0       83.2  52.406  &lt; 2e-16 ***
## poly(juice, 5)1 -16750.2      941.3 -17.796  &lt; 2e-16 ***
## poly(juice, 5)2   4750.6      941.3   5.047 1.59e-06 ***
## poly(juice, 5)3   3945.6      941.3   4.192 5.27e-05 ***
## poly(juice, 5)4  -3371.2      941.3  -3.582 0.000492 ***
## poly(juice, 5)5   1057.3      941.3   1.123 0.263509    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 941.3 on 122 degrees of freedom
## Multiple R-squared:  0.7539, Adjusted R-squared:  0.7439 
## F-statistic: 74.76 on 5 and 122 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Poly5</code></pre></div>
<pre><code>## Linear Regression 
## 
## 128 samples
##   1 predictor
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 128, 128, 128, 128, 128, 128, ... 
## Resampling results:
## 
##   RMSE      Rsquared 
##   981.9573  0.7238476
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE
## </code></pre>
<p>Мы получили в точности те же коэффициенты модели, что и при использовании базовой функции <code>lm()</code>, но для критериев <code>RMSE</code> и <code>RSquared</code> были найдены стандартные ошибки, позволяющие рассчитать доверительные интервалы этих статистик. Оценка проводилась по результатам 25 бутстреп-итераций, выполняемых функцией <code>train()</code> по умолчанию. Обратите внимание, что несмещенное бутстреп-значение коэффициента детерминации (0.734) несколько меньше, чем рассчитанное функцией <code>summary()</code> для финальной модели (0.754). В заключении приведем сокращенную таблицу доступных в <code>train()</code> моделей с указанием наименований их параметров. С нашей точки зрения, таблица полезна также тем, что является своеобразным путеводителем по пакетам R и реализованным в них статистическим методам. В последующих разделах мы приведем описание большинства перечисленных методов и продемонстрируем процесс оптимизации их параметров с помощью функции <code>train()</code>.</p>
<p>Список методов, моделей и их параметров, оптимизируемых с использованием функции <code>train()</code></p>
<table>
<thead>
<tr class="header">
<th align="left">﻿Модели</th>
<th align="center">Значение method</th>
<th align="center">Пакет</th>
<th align="center">Оптимизируемые параметры</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Деревья на основе рекурсивного деления (recursive partitioning)</td>
<td align="center">rpart</td>
<td align="center">rpart</td>
<td align="center">maxdepth</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">ctree</td>
<td align="center">party</td>
<td align="center">mincriterion</td>
</tr>
<tr class="odd">
<td align="left">Бустинг деревьев (boosted trees)</td>
<td align="center">gbm</td>
<td align="center">gbm</td>
<td align="center">interaction.depth, n.trees, shrinkage</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">blackboost</td>
<td align="center">mboost</td>
<td align="center">maxdepth, mstop</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">ada</td>
<td align="center">ada</td>
<td align="center">maxdepth, iter, nu</td>
</tr>
<tr class="even">
<td align="left">Другие модели бустинга (other boosted models)</td>
<td align="center">glmboost</td>
<td align="center">mboost</td>
<td align="center">mstop</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">gamboost</td>
<td align="center">mboost</td>
<td align="center">mstop</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">logitboost</td>
<td align="center">caTools</td>
<td align="center">nIter</td>
</tr>
<tr class="odd">
<td align="left">Случайный лес (random forest)</td>
<td align="center">rf</td>
<td align="center">randomForest</td>
<td align="center">mtry</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center">cforest</td>
<td align="center">party</td>
<td align="center">mtry</td>
</tr>
<tr class="odd">
<td align="left">Бэггинг-деревья (bagged trees)</td>
<td align="center">treebag</td>
<td align="center">ipred</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">Нейронные сети (neural networks)</td>
<td align="center">nnet</td>
<td align="center">nnet</td>
<td align="center">decay, size</td>
</tr>
<tr class="odd">
<td align="left">Частные наименьшие квадраты (partial least squares)</td>
<td align="center">pls</td>
<td align="center">pls, caret</td>
<td align="center">ncomp</td>
</tr>
<tr class="even">
<td align="left">Машина опорных векторов с RBF ядром (support vector machines RBF kernel)</td>
<td align="center">svmRadial</td>
<td align="center">kernlab</td>
<td align="center">sigma, C</td>
</tr>
<tr class="odd">
<td align="left">Машина опорных векторов с полиномиальным ядром (support vector machines polynomial kernel)</td>
<td align="center">svmPoly</td>
<td align="center">kernlab</td>
<td align="center">scale, degree, C</td>
</tr>
<tr class="even">
<td align="left">Гауссовы процессы с RBF ядром (Gaussian processes with RBF kernel)</td>
<td align="center">gaussprRadial</td>
<td align="center">kernlab</td>
<td align="center">sigma</td>
</tr>
<tr class="odd">
<td align="left">Гауссовы процессы с полиномиальным ядром (Gaussian processes with polynomial kernel)</td>
<td align="center">gaussprPoly</td>
<td align="center">kernlab</td>
<td align="center">scale, degree</td>
</tr>
<tr class="even">
<td align="left">Линейные модели наименьших квадратов (linear least squares)</td>
<td align="center">lm</td>
<td align="center">stats</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">Многомерные адаптивные регрессионные сплайны (multivariate adaptive regression splines MARS)</td>
<td align="center">earth, mars</td>
<td align="center">earth</td>
<td align="center">degree, nprune</td>
</tr>
<tr class="even">
<td align="left">Бэггинг-сплайны MARS (bagged MARS)</td>
<td align="center">bagEarth</td>
<td align="center">caret, earth</td>
<td align="center">degree, nprune</td>
</tr>
<tr class="odd">
<td align="left">Эластичные сети (elastic net)</td>
<td align="center">enet</td>
<td align="center">elasticnet</td>
<td align="center">lambda, fraction</td>
</tr>
<tr class="even">
<td align="left">Лассо (the lasso)</td>
<td align="center">lasso</td>
<td align="center">elasticnet</td>
<td align="center">fraction</td>
</tr>
<tr class="odd">
<td align="left">Машины релевантных векторов с RBF ядром (relevance vector machines RBF kernel)</td>
<td align="center">rvmRadial</td>
<td align="center">kernlab</td>
<td align="center">sigma</td>
</tr>
<tr class="even">
<td align="left">Машины релевантных векторов с полиномиальным ядром (relevance vector machines polynomial kernel</td>
<td align="center">rvmPoly</td>
<td align="center">kernlab</td>
<td align="center">scale, degree</td>
</tr>
<tr class="odd">
<td align="left">Линейный дискриминантный анализ (linear discriminant analysis)</td>
<td align="center">lda</td>
<td align="center">MASS</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">Пошаговый диагональный дискриминантный анализ (stepwise diagonal discriminant analysis)</td>
<td align="center">sddaLDA, sddaQDA</td>
<td align="center">SDDA</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">Логистическая регрессия для двух или более классов (logistic/multinomial regression)</td>
<td align="center">multinom</td>
<td align="center">nnet</td>
<td align="center">decay</td>
</tr>
<tr class="even">
<td align="left">Регуляризованный дискриминантный анализ (Regularized discriminant analysis)</td>
<td align="center">rda</td>
<td align="center">klaR</td>
<td align="center">lambda, gamma</td>
</tr>
<tr class="odd">
<td align="left">Гибкий дискриминантный анализ (Flexible discriminant analysis FDA)</td>
<td align="center">fda</td>
<td align="center">mda, earth</td>
<td align="center">degree, nprune</td>
</tr>
<tr class="even">
<td align="left">FDA на основе бэггинга (bagged FDA)</td>
<td align="center">bagFDA</td>
<td align="center">caret, earth</td>
<td align="center">degree, nprune</td>
</tr>
<tr class="odd">
<td align="left">Машины опорных векторов на основе метода наименьших квадратов c RBF ядром (least squares support vector machines RBF kernel)</td>
<td align="center">lssvmRadial</td>
<td align="center">kernlab</td>
<td align="center">sigma</td>
</tr>
<tr class="even">
<td align="left">Метод k-ближайших соседей (k nearest neighbors)</td>
<td align="center">knnЗ</td>
<td align="center">caret</td>
<td align="center">k</td>
</tr>
<tr class="odd">
<td align="left">Разделение по центроидам (nearest shrunken centroids)</td>
<td align="center">pam</td>
<td align="center">pamr</td>
<td align="center">threshold</td>
</tr>
<tr class="even">
<td align="left">Наивный байесовский классификатор (naive Bayes)</td>
<td align="center">nb</td>
<td align="center">klaR</td>
<td align="center">usekernel</td>
</tr>
<tr class="odd">
<td align="left">Обобщенный метод частных наименьших квадратов (Generalized partial least squares)</td>
<td align="center">gpls</td>
<td align="center">gpls</td>
<td align="center">K.prov</td>
</tr>
<tr class="even">
<td align="left">Сети с квантованием обучающего вектора (learned vector quantization)</td>
<td align="center">lvq</td>
<td align="center">class</td>
<td align="center">k</td>
</tr>
</tbody>
</table>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="034-Handling-Missing-Values.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="041-Regression-Models.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
