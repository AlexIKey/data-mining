<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Классификация, регрессия и другие алгоритмы Data Mining с использованием R</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Реализация алгоритмов Data Mining с использованием R">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Классификация, регрессия и другие алгоритмы Data Mining с использованием R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://ranalytics.github.io/data-mining/" />
  
  <meta property="og:description" content="Реализация алгоритмов Data Mining с использованием R" />
  <meta name="github-repo" content="ranalytics/data-mining" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Классификация, регрессия и другие алгоритмы Data Mining с использованием R" />
  
  <meta name="twitter:description" content="Реализация алгоритмов Data Mining с использованием R" />
  

<meta name="author" content="Шитиков В. К., Мастицкий С. Э.">


<meta name="date" content="2017-04-06">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="084-GLM-for-Counts.html">
<link rel="next" href="091-Data-Transformation.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Аннотация</a></li>
<li class="chapter" data-level="1" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html"><i class="fa fa-check"></i><b>1</b> Реализация моделей Data Mining в среде R (вместо предисловия)</a><ul>
<li class="chapter" data-level="1.1" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#section_1_1"><i class="fa fa-check"></i><b>1.1</b> Data Mining как направление анализа данных</a><ul>
<li class="chapter" data-level="1.1.1" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#sec_1_1_1"><i class="fa fa-check"></i><b>1.1.1</b> От статистического анализа разового эксперимента к Data Mining</a></li>
<li class="chapter" data-level="1.1.2" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#sec_1_1_2"><i class="fa fa-check"></i><b>1.1.2</b> Принципиальная множественность моделей окружающего мира</a></li>
<li class="chapter" data-level="1.1.3" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#sec_1_1_3"><i class="fa fa-check"></i><b>1.1.3</b> Нарастающая множественность алгоритмов построения моделей</a></li>
<li class="chapter" data-level="1.1.4" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#sec_1_1_4"><i class="fa fa-check"></i><b>1.1.4</b> Типы и характеристики групп моделей Data Mining</a></li>
<li class="chapter" data-level="1.1.5" data-path="01-Data-Mining-Models-in-R.html"><a href="01-Data-Mining-Models-in-R.html#sec_1_1_5"><i class="fa fa-check"></i><b>1.1.5</b> Природа многомерного отклика и его моделирование</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="012-R-Intro.html"><a href="012-R-Intro.html"><i class="fa fa-check"></i><b>1.2</b> Статистическая среда R и ее использование в Data Mining</a></li>
<li class="chapter" data-level="1.3" data-path="013-What-This-Book-Is-About.html"><a href="013-What-This-Book-Is-About.html"><i class="fa fa-check"></i><b>1.3</b> О чем эта книга и чего в ней нет</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="021-Model-Quality-Criteria.html"><a href="021-Model-Quality-Criteria.html"><i class="fa fa-check"></i><b>2</b> Статистические модели: критерии и методы оценивания их качества</a><ul>
<li class="chapter" data-level="2.1" data-path="021-Model-Quality-Criteria.html"><a href="021-Model-Quality-Criteria.html#sec_2_1"><i class="fa fa-check"></i><b>2.1</b> Основные шаги построения и верификации моделей</a></li>
<li class="chapter" data-level="2.2" data-path="022-Resampling-Techniques.html"><a href="022-Resampling-Techniques.html"><i class="fa fa-check"></i><b>2.2</b> Использование алгоритмов ресэмплинга для тестирования моделей и оптимизации их параметров</a></li>
<li class="chapter" data-level="2.3" data-path="023-Models-for-Class-Prediction.html"><a href="023-Models-for-Class-Prediction.html"><i class="fa fa-check"></i><b>2.3</b> Модели для предсказания класса объектов</a></li>
<li class="chapter" data-level="2.4" data-path="024-Projecting-Data-onto-a-Plane.html"><a href="024-Projecting-Data-onto-a-Plane.html"><i class="fa fa-check"></i><b>2.4</b> Проецирование многомерных данных на плоскости</a></li>
<li class="chapter" data-level="2.5" data-path="025-MV-analysis.html"><a href="025-MV-analysis.html"><i class="fa fa-check"></i><b>2.5</b> Многомерный статистический анализ данных</a></li>
<li class="chapter" data-level="2.6" data-path="026-Clustering-Methods.html"><a href="026-Clustering-Methods.html"><i class="fa fa-check"></i><b>2.6</b> Методы кластеризации</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="031-Intro-to-Caret.html"><a href="031-Intro-to-Caret.html"><i class="fa fa-check"></i><b>3</b> Пакет <code>caret</code> - инструмент построения статистических моделей в R</a><ul>
<li class="chapter" data-level="3.1" data-path="031-Intro-to-Caret.html"><a href="031-Intro-to-Caret.html#---------caret"><i class="fa fa-check"></i><b>3.1</b> Универсальный интерфейс доступа к функциям машинного обучения в пакете <code id="sec_3_1">caret</code></a></li>
<li class="chapter" data-level="3.2" data-path="032-Removing-Predictors.html"><a href="032-Removing-Predictors.html"><i class="fa fa-check"></i><b>3.2</b> Обнаружение и удаление “ненужных” предикторов</a></li>
<li class="chapter" data-level="3.3" data-path="033-Preprocessing.html"><a href="033-Preprocessing.html"><i class="fa fa-check"></i><b>3.3</b> Предварительная обработка: преобразование и групповая трансформация переменных</a></li>
<li class="chapter" data-level="3.4" data-path="034-Handling-Missing-Values.html"><a href="034-Handling-Missing-Values.html"><i class="fa fa-check"></i><b>3.4</b> Заполнение пропущенных значений в данных</a></li>
<li class="chapter" data-level="3.5" data-path="035-The-train-Functions.html"><a href="035-The-train-Functions.html"><i class="fa fa-check"></i><b>3.5</b> Функция <code>train()</code> из пакета <code id="sec_3_5">caret</code></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html"><i class="fa fa-check"></i><b>4</b> Построение регрессионных моделей различного типа</a><ul>
<li class="chapter" data-level="4.1" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html#sec_4_1"><i class="fa fa-check"></i><b>4.1</b> Селекция оптимального набора предикторов линейной модели</a><ul>
<li class="chapter" data-level="4.1.1" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html#sec_4_1_1"><i class="fa fa-check"></i><b>4.1.1</b> Полная регрессионная модель и пошаговая процедура</a></li>
<li class="chapter" data-level="4.1.2" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html#sec_4_1_2"><i class="fa fa-check"></i><b>4.1.2</b> Рекурсивное исключение переменных</a></li>
<li class="chapter" data-level="4.1.3" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html#sec_4_1_3"><i class="fa fa-check"></i><b>4.1.3</b> Генетический алгоритм</a></li>
<li class="chapter" data-level="4.1.4" data-path="041-Regression-Models.html"><a href="041-Regression-Models.html#sec_4_1_4"><i class="fa fa-check"></i><b>4.1.4</b> Тестирование моделей с использованием дополнительного набора данных</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="042-Regularization.html"><a href="042-Regularization.html"><i class="fa fa-check"></i><b>4.2</b> Регуляризация, частные наименьшие квадраты и kNN-регрессия</a><ul>
<li class="chapter" data-level="4.2.1" data-path="042-Regularization.html"><a href="042-Regularization.html#sec_4_2_1"><i class="fa fa-check"></i><b>4.2.1</b> Регрессия по методу “лассо”</a></li>
<li class="chapter" data-level="4.2.2" data-path="042-Regularization.html"><a href="042-Regularization.html#sec_4_2_2"><i class="fa fa-check"></i><b>4.2.2</b> Метод частных наименьших квадратов (PLS)</a></li>
<li class="chapter" data-level="4.2.3" data-path="042-Regularization.html"><a href="042-Regularization.html#sec_4_2_3"><i class="fa fa-check"></i><b>4.2.3</b> Регрессия по методу <em>k</em> ближайших соседей</a></li>
<li class="chapter" data-level="4.2.4" data-path="042-Regularization.html"><a href="042-Regularization.html#sec_4_2_4"><i class="fa fa-check"></i><b>4.2.4</b> Тестирование моделей с использованием дополнительного набора данных</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="043-Decision-Trees.html"><a href="043-Decision-Trees.html"><i class="fa fa-check"></i><b>4.3</b> Построение деревьев регрессии</a><ul>
<li class="chapter" data-level="4.3.1" data-path="043-Decision-Trees.html"><a href="043-Decision-Trees.html#sec_4_3_1"><i class="fa fa-check"></i><b>4.3.1</b> Построение деревьев на основе рекурсивного разбиения</a></li>
<li class="chapter" data-level="4.3.2" data-path="043-Decision-Trees.html"><a href="043-Decision-Trees.html#sec_4_3_2"><i class="fa fa-check"></i><b>4.3.2</b> Построение деревьев с использованием алгортма условного вывода</a></li>
<li class="chapter" data-level="4.3.3" data-path="043-Decision-Trees.html"><a href="043-Decision-Trees.html#sec_4_3_3"><i class="fa fa-check"></i><b>4.3.3</b> Тестирование моделей с использованием дополнительного набора данных</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="044-Ensembles.html"><a href="044-Ensembles.html"><i class="fa fa-check"></i><b>4.4</b> Ансамбли моделей: бэггинг, случайные леса, бустинг</a><ul>
<li class="chapter" data-level="4.4.1" data-path="044-Ensembles.html"><a href="044-Ensembles.html#sec_4_4_1"><i class="fa fa-check"></i><b>4.4.1</b> Бэггинг и случайные леса</a></li>
<li class="chapter" data-level="4.4.2" data-path="044-Ensembles.html"><a href="044-Ensembles.html#sec_4_4_2"><i class="fa fa-check"></i><b>4.4.2</b> Бустинг</a></li>
<li class="chapter" data-level="4.4.3" data-path="044-Ensembles.html"><a href="044-Ensembles.html#sec_4_4_3"><i class="fa fa-check"></i><b>4.4.3</b> Тестирование моделей с использованием дополнительного набора данных</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="045-Comparing-Trees.html"><a href="045-Comparing-Trees.html"><i class="fa fa-check"></i><b>4.5</b> Сравнение построенных моделей и оценка информативности предикторов</a></li>
<li class="chapter" data-level="4.6" data-path="046-MV-Trees.html"><a href="046-MV-Trees.html"><i class="fa fa-check"></i><b>4.6</b> Деревья регрессии с многомерным откликом</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="051-Association-Rules.html"><a href="051-Association-Rules.html"><i class="fa fa-check"></i><b>5</b> Бинарные матрицы и ассоциативные правила</a><ul>
<li class="chapter" data-level="5.1" data-path="051-Association-Rules.html"><a href="051-Association-Rules.html#sec_5_1"><i class="fa fa-check"></i><b>5.1</b> Классификация в бинарных пространствах с использованием классических моделей</a></li>
<li class="chapter" data-level="5.2" data-path="052-Binary-Decision-Trees.html"><a href="052-Binary-Decision-Trees.html"><i class="fa fa-check"></i><b>5.2</b> Бинарные деревья решений</a></li>
<li class="chapter" data-level="5.3" data-path="053-Logic-Rules.html"><a href="053-Logic-Rules.html"><i class="fa fa-check"></i><b>5.3</b> Поиск логических закономерностей в данных</a></li>
<li class="chapter" data-level="5.4" data-path="054-Association-Rules-Algos.html"><a href="054-Association-Rules-Algos.html"><i class="fa fa-check"></i><b>5.4</b> Алгоритмы выделения ассоциативных правил</a></li>
<li class="chapter" data-level="5.5" data-path="055-Traminer.html"><a href="055-Traminer.html"><i class="fa fa-check"></i><b>5.5</b> Анализ последовательностей знаков или событий</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="061-Binary-Classifiers.html"><a href="061-Binary-Classifiers.html"><i class="fa fa-check"></i><b>6</b> Бинарные классификаторы с различными разделяющими поверхностями</a><ul>
<li class="chapter" data-level="6.1" data-path="061-Binary-Classifiers.html"><a href="061-Binary-Classifiers.html#sec_6_1"><i class="fa fa-check"></i><b>6.1</b> Дискриминантный анализ</a></li>
<li class="chapter" data-level="6.2" data-path="062-SVM.html"><a href="062-SVM.html"><i class="fa fa-check"></i><b>6.2</b> Дискриминантный анализ</a></li>
<li class="chapter" data-level="6.3" data-path="063-Nonlinear-Borders.html"><a href="063-Nonlinear-Borders.html"><i class="fa fa-check"></i><b>6.3</b> Ядерные функции машины опорных векторов</a></li>
<li class="chapter" data-level="6.4" data-path="064-Classification-Trees.html"><a href="064-Classification-Trees.html"><i class="fa fa-check"></i><b>6.4</b> Деревья классификации, случайный лес и логистическая регрессия</a></li>
<li class="chapter" data-level="6.5" data-path="065-Comparing-Classifiers.html"><a href="065-Comparing-Classifiers.html"><i class="fa fa-check"></i><b>6.5</b> Процедуры сравнения эффективности моделей классификации</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="071-Multiclass-Classification.html"><a href="071-Multiclass-Classification.html"><i class="fa fa-check"></i><b>7</b> Модели классификации для нескольких классов</a><ul>
<li class="chapter" data-level="7.1" data-path="071-Multiclass-Classification.html"><a href="071-Multiclass-Classification.html#sec_7_1"><i class="fa fa-check"></i><b>7.1</b> Ирисы Фишера и метод <em>k</em> ближайших соседей</a></li>
<li class="chapter" data-level="7.2" data-path="072-NBC.html"><a href="072-NBC.html"><i class="fa fa-check"></i><b>7.2</b> Наивный байесовский классификатор</a></li>
<li class="chapter" data-level="7.3" data-path="073-In-Discriminant-Space.html"><a href="073-In-Discriminant-Space.html"><i class="fa fa-check"></i><b>7.3</b> Классификация в линейном дискриминантном пространстве</a></li>
<li class="chapter" data-level="7.4" data-path="074-Nonlinear-Classifiers.html"><a href="074-Nonlinear-Classifiers.html"><i class="fa fa-check"></i><b>7.4</b> Нелинейные классификаторы в R</a></li>
<li class="chapter" data-level="7.5" data-path="075-Multinomial-Logit.html"><a href="075-Multinomial-Logit.html"><i class="fa fa-check"></i><b>7.5</b> Модель мультиномиального логита</a></li>
<li class="chapter" data-level="7.6" data-path="076-NN.html"><a href="076-NN.html"><i class="fa fa-check"></i><b>7.6</b> Классификаторы на основе искусственных нейронных сетей</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="081-Logit-for-Count.html"><a href="081-Logit-for-Count.html"><i class="fa fa-check"></i><b>8</b> Моделирование порядковых и счетных переменных</a><ul>
<li class="chapter" data-level="8.1" data-path="081-Logit-for-Count.html"><a href="081-Logit-for-Count.html#sec_8_1"><i class="fa fa-check"></i><b>8.1</b> Модель логита для порядковой переменной</a></li>
<li class="chapter" data-level="8.2" data-path="082-NN-with-Caret.html"><a href="082-NN-with-Caret.html"><i class="fa fa-check"></i><b>8.2</b> Настройка параметров нейронных сетей средствами пакета <code id="sec_8_2">caret</code></a></li>
<li class="chapter" data-level="8.3" data-path="083-Model-Complexes.html"><a href="083-Model-Complexes.html"><i class="fa fa-check"></i><b>8.3</b> Методы комплексации модельных прогнозов</a></li>
<li class="chapter" data-level="8.4" data-path="084-GLM-for-Counts.html"><a href="084-GLM-for-Counts.html"><i class="fa fa-check"></i><b>8.4</b> Обобщенные линейные модели для счетных данных</a></li>
<li class="chapter" data-level="8.5" data-path="085-ZIP-for-Counts.html"><a href="085-ZIP-for-Counts.html"><i class="fa fa-check"></i><b>8.5</b> ZIP- и барьерные модели счетных данных</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="091-Data-Transformation.html"><a href="091-Data-Transformation.html"><i class="fa fa-check"></i><b>9</b> Методы многомерной ординации</a><ul>
<li class="chapter" data-level="9.1" data-path="091-Data-Transformation.html"><a href="091-Data-Transformation.html#sec_9_1"><i class="fa fa-check"></i><b>9.1</b> Преобразование данных и вычисление матрицы расстояний</a></li>
<li class="chapter" data-level="9.2" data-path="092-Distance-ANOVA.html"><a href="092-Distance-ANOVA.html"><i class="fa fa-check"></i><b>9.2</b> Непараметрический дисперсионный анализ матриц дистанций</a></li>
<li class="chapter" data-level="9.3" data-path="093-Comparing-Diagrams.html"><a href="093-Comparing-Diagrams.html"><i class="fa fa-check"></i><b>9.3</b> Методы ординации объектов и переменных: построение и сравнение диаграмм</a></li>
<li class="chapter" data-level="9.4" data-path="094-Ordination-Factors.html"><a href="094-Ordination-Factors.html"><i class="fa fa-check"></i><b>9.4</b> Оценка связи ординации с внешними факторами</a></li>
<li class="chapter" data-level="9.5" data-path="095-NMDS.html"><a href="095-NMDS.html"><i class="fa fa-check"></i><b>9.5</b> Неметрическое многомерное шкалирование и построение распределения чувствительности видов</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="101-Partitioning-Algos.html"><a href="101-Partitioning-Algos.html"><i class="fa fa-check"></i><b>10</b> Кластерный анализ</a><ul>
<li class="chapter" data-level="10.1" data-path="101-Partitioning-Algos.html"><a href="101-Partitioning-Algos.html#sec_10_1"><i class="fa fa-check"></i><b>10.1</b> Алгоритмы кластеризации, основанные на разделении</a></li>
<li class="chapter" data-level="10.2" data-path="102-H-Clustering.html"><a href="102-H-Clustering.html"><i class="fa fa-check"></i><b>10.2</b> Иерархическая кластеризация</a></li>
<li class="chapter" data-level="10.3" data-path="103-Clustering-Quality.html"><a href="103-Clustering-Quality.html"><i class="fa fa-check"></i><b>10.3</b> Оценка качества кластеризации</a></li>
<li class="chapter" data-level="10.4" data-path="104-Other-Clustering-Methods.html"><a href="104-Other-Clustering-Methods.html"><i class="fa fa-check"></i><b>10.4</b> Другие алгоритмы кластеризации</a><ul>
<li class="chapter" data-level="10.4.1" data-path="104-Other-Clustering-Methods.html"><a href="104-Other-Clustering-Methods.html#sec_10_4_1"><i class="fa fa-check"></i><b>10.4.1</b> Иерархическая кластеризация на главные компоненты</a></li>
<li class="chapter" data-level="10.4.2" data-path="104-Other-Clustering-Methods.html"><a href="104-Other-Clustering-Methods.html#sec_10_4_2"><i class="fa fa-check"></i><b>10.4.2</b> Метод нечетких <em>k</em> средних (fuzzy analysis clustering)</a></li>
<li class="chapter" data-level="10.4.3" data-path="104-Other-Clustering-Methods.html"><a href="104-Other-Clustering-Methods.html#sec_10_4_3"><i class="fa fa-check"></i><b>10.4.3</b> Статистическая модель кластеризации</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="105-Cohonen-Maps.html"><a href="105-Cohonen-Maps.html"><i class="fa fa-check"></i><b>10.5</b> Самоорганизующиеся карты Кохонена</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="111-Rattle-Intro.html"><a href="111-Rattle-Intro.html"><i class="fa fa-check"></i><b>11</b> <code>rattle</code>: графический интерфейс R для реализации алгоритмов Data Mining</a><ul>
<li class="chapter" data-level="11.1" data-path="111-Rattle-Intro.html"><a href="111-Rattle-Intro.html#----rattle"><i class="fa fa-check"></i><b>11.1</b> Начало работы с пакетом <code id="sec_11_1">rattle</code></a></li>
<li class="chapter" data-level="11.2" data-path="112-Descriptive-Stats.html"><a href="112-Descriptive-Stats.html"><i class="fa fa-check"></i><b>11.2</b> Описательная статистика и визуализация данных</a></li>
<li class="chapter" data-level="11.3" data-path="113-Model-Building.html"><a href="113-Model-Building.html"><i class="fa fa-check"></i><b>11.3</b> Построение и тестирование моделей классификации</a></li>
<li class="chapter" data-level="11.4" data-path="114-Descriptive-Models.html"><a href="114-Descriptive-Models.html"><i class="fa fa-check"></i><b>11.4</b> Дескриптивные модели (обучение без учителя)</a><ul>
<li class="chapter" data-level="11.4.1" data-path="114-Descriptive-Models.html"><a href="114-Descriptive-Models.html#sec_11_4_1"><i class="fa fa-check"></i><b>11.4.1</b> Кластерный анализ</a></li>
<li class="chapter" data-level="11.4.2" data-path="114-Descriptive-Models.html"><a href="114-Descriptive-Models.html#sec_11_4_2"><i class="fa fa-check"></i><b>11.4.2</b> Ассоциативные правила</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="120-References.html"><a href="120-References.html"><i class="fa fa-check"></i><b>12</b> Список рекомендуемой литературы</a></li>
<li class="chapter" data-level="" data-path="130-Appendix.html"><a href="130-Appendix.html"><i class="fa fa-check"></i>Приложение: cправочная карта по Data Mining с использованием R</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Классификация, регрессия и другие алгоритмы Data Mining с использованием R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec_8_5" class="section level2">
<h2><span class="header-section-number">8.5</span> ZIP- и барьерные модели счетных данных</h2>
<p>Как обсуждалось выше, реальные данные часто характеризуются существенными отклонениями от теоретического однопараметрического распределения Пуассона: избытком нулевых значений и/или нарушениями предположения о параметре дисперсии <span class="math inline">\(\text{Var}(Y) \neq E(Y)\)</span>. Учесть повышенную разреженность данных можно с использованием <em>модели Пуассона со смешанными параметрами</em>, учитывающей избыток нулей (Zero Inflated Poisson, ZIP), или специальной двухкомпонентной <em>модели с измененными нулями</em> (Zero-altered Poisson, ZAP), которую часто называют “барьерной” моделью (hurdle model). Если наряду с избытком нулей имеет место отчетливая избыточная дисперсия, то можно воспользоваться соответствующими моделями на основе отрицательного биномиального распределения: ZINB (Zero-inﬂated Negative Binomial) и ZANB (Zero-altered Negative Binomial). Эти четыре модели будут предметом нашего дальнейшего обсуждения (подробности см. в Zeileis et al., 2008; Zuur et al., 2009; Cameron, Trivedi, 2013; Кшнясев, 2010).</p>
<p>Рассмотрим в качестве примера таблицу <code>NMES1988</code> из пакета <code>AER</code>, содержащий данные о визитах 4406 респондентов старше 66 лет в учреждения бесплатного медицинского обслуживания США в 1988 г. Число посещений <code>visits</code> примем в качестве отклика, а три метрических переменных и три фактора используем в качестве предикторов:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(AER)
<span class="kw">data</span>(<span class="st">&quot;NMES1988&quot;</span>)        <span class="co"># Загружаем данные и отбираем столбцы</span>
nmes &lt;-<span class="st"> </span>NMES1988[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span>:<span class="dv">8</span>, <span class="dv">13</span>, <span class="dv">15</span>, <span class="dv">18</span>)]
<span class="kw">sum</span>(nmes$visits &lt;<span class="st"> </span><span class="dv">1</span>)   <span class="co"># наблюдаемое число нулей</span></code></pre></div>
<pre><code>## [1] 683</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">table</span>(nmes$visits))  </code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig-8-9"></span>
<img src="085-ZIP-for-Counts_files/figure-html/fig-8-9-1.png" alt="Наблюдаемые частоты посещений врача" width="576" />
<p class="caption">
Рисунок 8.9: Наблюдаемые частоты посещений врача
</p>
</div>
<p>Вычислим теоретическую частоту нулевых значений:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod1 &lt;-<span class="st"> </span><span class="kw">glm</span>(visits ~<span class="st"> </span>., <span class="dt">data =</span> nmes, <span class="dt">family =</span> <span class="st">&quot;poisson&quot;</span>)
mu &lt;-<span class="st"> </span><span class="kw">predict</span>(mod1, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>) <span class="co"># среднее Пуассона</span>
exp &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">dpois</span>(<span class="dt">x =</span> <span class="dv">0</span>, <span class="dt">lambda =</span> mu))  <span class="co"># теоретическая частота</span>
<span class="kw">round</span>(exp)                             <span class="co"># нулевых значений</span></code></pre></div>
<pre><code>## [1] 47</code></pre>
<p>Модели ZIP и ZINB называют моделями со смешанными параметрами (mixture models), поскольку присутствие нулей считается итогом двух различных процессов: биномиального процесса и процесса формирования счетной случайной величины. Здесь биномиальный процесс моделирует вероятность измерения ложно-положительного результата против всех других типов данных (включая истинные нули и конкретные счетные значения). Иными словами, мы делим данные на три воображаемые группы: первая группа содержит только ложные нули – наблюдения с вероятностью появления <span class="math inline">\(\pi_i\)</span>, вторая группа - истинные нули с вероятностью <span class="math inline">\((pi_i - 1)\)</span>, и третья группа - ненулевые наблюдения, которые (вместе со второй группой!) моделируются регрессией Пуассона с учетом независимых переменных. Тогда распределение вероятностей по ZIP-модели определяется следующими выражениями:</p>
<p><span class="math display">\[P(y_i = 0) = \pi_i + (1 + \pi_i) \times e^{-\mu_i}, \, \, \, \mu_i = e^{\alpha + \beta_1 x_{1i} + \beta_2 x_{2i}  + \dots}\]</span></p>
<p><span class="math display">\[P(Y_i = y_i | y_i &gt; 0) = (1 - \pi_i) \times \frac{\mu^{y_i} \times e^{-\mu_i}}{y_i!}, \, \, \, \pi_i = \frac{e^{\nu}}{1 + e^{\nu}}.\]</span></p>
<p>Модель ZINB формулируется так же, но значение <span class="math inline">\(\mu_i\)</span> подгоняется с использованием отрицательного биномиального распределения.</p>
<p>Построение моделей с избыточными нулями осуществляется с использованием функции <code>zeroinfl()</code> из пакета <code>pscl</code>, для чего необходимо выполнить следующий код:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pscl)
M.ZIP &lt;-<span class="st"> </span><span class="kw">zeroinfl</span>(visits ~<span class="st"> </span>., <span class="dt">data =</span> nmes, <span class="dt">dist =</span> <span class="st">&quot;poisson&quot;</span>, <span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>)
<span class="kw">summary</span>(M.ZIP)</code></pre></div>
<pre><code>## 
## Call:
## zeroinfl(formula = visits ~ ., data = nmes, dist = &quot;poisson&quot;, link = &quot;logit&quot;)
## 
## Pearson residuals:
##     Min      1Q  Median      3Q     Max 
## -5.4092 -1.1579 -0.4769  0.5435 25.0380 
## 
## Count model coefficients (poisson with log link):
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      1.405812   0.024175  58.152  &lt; 2e-16 ***
## hospital         0.159011   0.006060  26.239  &lt; 2e-16 ***
## healthpoor       0.253454   0.017705  14.315  &lt; 2e-16 ***
## healthexcellent -0.304134   0.031151  -9.763  &lt; 2e-16 ***
## chronic          0.101836   0.004721  21.571  &lt; 2e-16 ***
## gendermale      -0.062332   0.013054  -4.775 1.80e-06 ***
## school           0.019144   0.001873  10.221  &lt; 2e-16 ***
## insuranceyes     0.080557   0.017145   4.699 2.62e-06 ***
## 
## Zero-inflation model coefficients (binomial with logit link):
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)     -0.08102    0.14233  -0.569 0.569219    
## hospital        -0.30330    0.09158  -3.312 0.000927 ***
## healthpoor       0.02166    0.16170   0.134 0.893431    
## healthexcellent  0.23786    0.14990   1.587 0.112550    
## chronic         -0.53117    0.04601 -11.545  &lt; 2e-16 ***
## gendermale       0.41527    0.08919   4.656 3.22e-06 ***
## school          -0.05677    0.01223  -4.640 3.49e-06 ***
## insuranceyes    -0.75294    0.10257  -7.341 2.12e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 
## 
## Number of iterations in BFGS optimization: 24 
## Log-likelihood: -1.613e+04 on 16 Df</code></pre>
<p>Построенная модель ZIP включает следующие статистически значимые переменные: время пребывания в больнице (<code>hospital</code>), оценка хроничности заболевания (<code>chronic</code>), длительности обучения (<code>school</code>), пола (<code>gender</code>), наличия страховки (<code>insurance</code>). Самооценка же здоровья (<code>health</code>) оказалась незначимой.</p>
<p>Аналогичным образом можно построить модель с использованием отрицательного биномиального распределения, которая имеет аналогичную структуру и поэтому полный протокол результатов не приводится:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">M.ZINB &lt;-<span class="st"> </span><span class="kw">zeroinfl</span>(visits ~<span class="st"> </span>., <span class="dt">data =</span> nmes, <span class="dt">dist =</span> <span class="st">&quot;negbin&quot;</span>, <span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>)
<span class="kw">summary</span>(M.ZINB) </code></pre></div>
<pre><code>## 
## Call:
## zeroinfl(formula = visits ~ ., data = nmes, dist = &quot;negbin&quot;, link = &quot;logit&quot;)
## 
## Pearson residuals:
##     Min      1Q  Median      3Q     Max 
## -1.1966 -0.7097 -0.2784  0.3256 17.7661 
## 
## Count model coefficients (negbin with log link):
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      1.193466   0.056737  21.035  &lt; 2e-16 ***
## hospital         0.201214   0.020392   9.867  &lt; 2e-16 ***
## healthpoor       0.287190   0.045940   6.251 4.07e-10 ***
## healthexcellent -0.313540   0.062977  -4.979 6.40e-07 ***
## chronic          0.128955   0.011938  10.802  &lt; 2e-16 ***
## gendermale      -0.080093   0.031035  -2.581  0.00986 ** 
## school           0.021338   0.004368   4.886 1.03e-06 ***
## insuranceyes     0.126815   0.041687   3.042  0.00235 ** 
## Log(theta)       0.394731   0.035145  11.231  &lt; 2e-16 ***
## 
## Zero-inflation model coefficients (binomial with logit link):
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)     -0.06354    0.27668  -0.230  0.81837    
## hospital        -0.81760    0.43875  -1.863  0.06240 .  
## healthpoor       0.10178    0.44071   0.231  0.81735    
## healthexcellent  0.10488    0.30965   0.339  0.73484    
## chronic         -1.24630    0.17918  -6.956 3.51e-12 ***
## gendermale       0.64937    0.20046   3.239  0.00120 ** 
## school          -0.08481    0.02676  -3.169  0.00153 ** 
## insuranceyes    -1.15808    0.22436  -5.162 2.45e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 
## 
## Theta = 1.484 
## Number of iterations in BFGS optimization: 31 
## Log-likelihood: -1.209e+04 on 17 Df</code></pre>
<p>Визуально сравнить степень согласия эмпирических и оцененных моделью частот можно с использованием гистограмм (поскольку для лучшего восприятия графика из частот извлекают квадратный корень, их называют еще “рутограммами” - от англ. “root”, корень):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># для инсталляции countreg выполните команду: </span>
<span class="co"># install.packages(&quot;countreg&quot;, repos=&quot;http://R-Forge.R-project.org&quot;)</span>
<span class="kw">library</span>(countreg)
<span class="kw">rootogram</span>(M.ZIP)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig-8-10"></span>
<img src="085-ZIP-for-Counts_files/figure-html/fig-8-10-1.png" alt="Рутограмма частот для модели ZIP" width="576" />
<p class="caption">
Рисунок 8.10: Рутограмма частот для модели ZIP
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rootogram</span>(M.ZINB)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig-8-11"></span>
<img src="085-ZIP-for-Counts_files/figure-html/fig-8-11-1.png" alt="Рутограмма частот для модели ZINB" width="576" />
<p class="caption">
Рисунок 8.11: Рутограмма частот для модели ZINB
</p>
</div>
<p>В результате введения в модель на основе отрицательного биномиального распределения ZINB дополнительного параметра <code>Theta</code>, компенсирующего избыточную дисперсию, оценки коэффициентов и их уровней значимостей были уточнены, максимум логарифма функции правдоподобия увеличился, а гистограмма на рис. <a href="085-ZIP-for-Counts.html#fig:fig-8-11">8.11</a> приобрела более плавный характер.</p>
<p>Заметим, что мы построили простейший вариант моделей, исходя из предположения о том, что параметр <span class="math inline">\(\pi_i\)</span> равен постоянному значению (т.е. <span class="math inline">\(\nu = const\)</span>). Изменяя структуру правой части объекта formula, мы можем задать любую зависимость для  от имеющихся ковариат (Zuur et al., 2009)</p>
<p>Барьерная модель по своему смыслу является уже не смешанной, а двухкомпонентной моделью, т.е. задается как комбинация двух самостоятельных уравнений регрессии: логит-регрессии для моделирования вероятности <span class="math inline">\(P(y_i = 0)\)</span> на основе биномиального распределения, и множественной регрессии для ненулевой средней численности в предположении одно- или двухпараметрического распределения для стохастической компоненты, например:</p>
<p><span class="math display">\[ f_{ZAP}(y; \beta, \gamma) =
  \begin{cases}
    f_{bin}(y = 0; \gamma)       &amp; \quad \text{для } y=0\\
    (1-f_{bin}(y = 0; \gamma))\times\frac{f_{Pois}(y;\beta)}{1-f_{Pois}(y;\beta)}  &amp; \quad \text{для } y&gt;0\\
  \end{cases}. \]</span></p>
<p>Выполним построение моделей ZAP и ZANB, для чего воспользуемся функцией <code>hurdle()</code> из пакета <code>pscl</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">M.ZAP &lt;-<span class="st">  </span><span class="kw">hurdle</span>(visits ~<span class="st"> </span>., <span class="dt">data =</span> nmes, 
                 <span class="dt">dist =</span> <span class="st">&quot;poisson&quot;</span>, <span class="dt">zero.dist =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>)
<span class="kw">summary</span>(M.ZAP)</code></pre></div>
<pre><code>## 
## Call:
## hurdle(formula = visits ~ ., data = nmes, dist = &quot;poisson&quot;, zero.dist = &quot;binomial&quot;, 
##     link = &quot;logit&quot;)
## 
## Pearson residuals:
##     Min      1Q  Median      3Q     Max 
## -5.4144 -1.1565 -0.4770  0.5432 25.0228 
## 
## Count model coefficients (truncated poisson with log link):
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      1.406459   0.024180  58.167  &lt; 2e-16 ***
## hospital         0.158967   0.006061  26.228  &lt; 2e-16 ***
## healthpoor       0.253521   0.017708  14.317  &lt; 2e-16 ***
## healthexcellent -0.303677   0.031150  -9.749  &lt; 2e-16 ***
## chronic          0.101720   0.004719  21.557  &lt; 2e-16 ***
## gendermale      -0.062247   0.013055  -4.768 1.86e-06 ***
## school           0.019078   0.001872  10.194  &lt; 2e-16 ***
## insuranceyes     0.080879   0.017139   4.719 2.37e-06 ***
## Zero hurdle model coefficients (binomial with logit link):
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      0.043147   0.139852   0.309 0.757688    
## hospital         0.312449   0.091437   3.417 0.000633 ***
## healthpoor      -0.008716   0.161024  -0.054 0.956833    
## healthexcellent -0.289570   0.142682  -2.029 0.042409 *  
## chronic          0.535213   0.045378  11.794  &lt; 2e-16 ***
## gendermale      -0.415658   0.087608  -4.745 2.09e-06 ***
## school           0.058541   0.011989   4.883 1.05e-06 ***
## insuranceyes     0.747120   0.100880   7.406 1.30e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 
## 
## Number of iterations in BFGS optimization: 14 
## Log-likelihood: -1.613e+04 on 16 Df</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">M.ZANB &lt;-<span class="st">  </span><span class="kw">hurdle</span> (visits ~<span class="st"> </span>., <span class="dt">data =</span> nmes, 
                   <span class="dt">dist =</span> <span class="st">&quot;negbin&quot;</span>, <span class="dt">link=</span><span class="st">&quot;logit&quot;</span>)
<span class="kw">summary</span>(M.ZANB)</code></pre></div>
<pre><code>## 
## Call:
## hurdle(formula = visits ~ ., data = nmes, dist = &quot;negbin&quot;, link = &quot;logit&quot;)
## 
## Pearson residuals:
##     Min      1Q  Median      3Q     Max 
## -1.1718 -0.7080 -0.2737  0.3196 18.0092 
## 
## Count model coefficients (truncated negbin with log link):
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      1.197699   0.058973  20.309  &lt; 2e-16 ***
## hospital         0.211898   0.021396   9.904  &lt; 2e-16 ***
## healthpoor       0.315958   0.048056   6.575 4.87e-11 ***
## healthexcellent -0.331861   0.066093  -5.021 5.14e-07 ***
## chronic          0.126421   0.012452  10.152  &lt; 2e-16 ***
## gendermale      -0.068317   0.032416  -2.108   0.0351 *  
## school           0.020693   0.004535   4.563 5.04e-06 ***
## insuranceyes     0.100172   0.042619   2.350   0.0188 *  
## Log(theta)       0.333255   0.042754   7.795 6.46e-15 ***
## Zero hurdle model coefficients (binomial with logit link):
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      0.043147   0.139852   0.309 0.757688    
## hospital         0.312449   0.091437   3.417 0.000633 ***
## healthpoor      -0.008716   0.161024  -0.054 0.956833    
## healthexcellent -0.289570   0.142682  -2.029 0.042409 *  
## chronic          0.535213   0.045378  11.794  &lt; 2e-16 ***
## gendermale      -0.415658   0.087608  -4.745 2.09e-06 ***
## school           0.058541   0.011989   4.883 1.05e-06 ***
## insuranceyes     0.747120   0.100880   7.406 1.30e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 
## 
## Theta: count = 1.3955
## Number of iterations in BFGS optimization: 16 
## Log-likelihood: -1.209e+04 on 17 Df</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">rootogram</span>(M.ZAP)
<span class="kw">rootogram</span>(M.ZANB)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig-8-12"></span>
<img src="085-ZIP-for-Counts_files/figure-html/fig-8-12-1.png" alt="Рутограмма частот моделей ZAP и ZANB" width="768" />
<p class="caption">
Рисунок 8.12: Рутограмма частот моделей ZAP и ZANB
</p>
</div>
<p>На вопрос о том, какая модель эффективнее, можно дать очевидный ответ (<code>M.ZANB</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fm &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;ZIP&quot;</span> =<span class="st"> </span>M.ZIP, <span class="st">&quot;ZINB&quot;</span> =<span class="st"> </span>M.ZINB, 
           <span class="st">&quot;Hurdle-Pois&quot;</span> =<span class="st"> </span>M.ZAP,  <span class="st">&quot;Hurdle-NB&quot;</span> =<span class="st"> </span>M.ZANB)
<span class="kw">rbind</span>(<span class="dt">logLik =</span> <span class="kw">sapply</span>(fm, function(x) <span class="kw">round</span>(<span class="kw">logLik</span>(x), <span class="dt">digits =</span> <span class="dv">0</span>)),
      <span class="dt">AIC =</span> <span class="kw">sapply</span>(fm, function(x) <span class="kw">round</span>(<span class="kw">AIC</span>(x), <span class="dt">digits =</span> <span class="dv">0</span>)))</code></pre></div>
<pre><code>##           ZIP   ZINB Hurdle-Pois Hurdle-NB
## logLik -16134 -12091      -16134    -12088
## AIC     32300  24215       32301     24210</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="084-GLM-for-Counts.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="091-Data-Transformation.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
